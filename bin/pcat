#!/usr/bin/env python
# coding: utf-8
""" pcat

First version by Daniele Trifir√≤ on 2013-08-17.
brethil@phy.olemiss.edu

Run with -h or --help for usage.

This is a wrapper the the other functions in the package.

PCAT Pipeline:
	1) Retrieve data 
		Read from the frame files (and save if requested) time series
		for the given time interval.
		
		Uses retrieve_timeseries() from `pcat.utils`
		
	2) Condition data 
		a conditioning_function() is defined based on the required
		processing, and data is prepared for analysis by calling
		conditioning_function().
		Uses various functions from `pcat.condition`
		
		Data conditioning and retriveval is sped up by launching multiple
		processes, defined by the PARALLEL_PROCESSES variable (see below).
		
	3) Create database
		Create a database from the previously processed data.
		
		Uses create_data_matrix(...), create_data_matrix_from_psd(...)
		from `pcat.utils`.
		
	4) Perform PCA
		Perform PCA on the database
		PCA(...) from `pcat.pca`
		
	5) Cluster the scores matrix from `pcat.pca`
		gaussian_mixture(...) from `pcat.gmm`
		
		Other clustering algorithms can be easily implemented
		by changing gaussian_mixture() with another function.
		For more see `pcat.gmm`
	
	6) Plot scatterplots (with image maps), time series
		scatterplot(...), spike_time_series(...), plot_psds(...)
		from `pcat.gmm`
	
	7) Print URL to analysis results.
		
"""

import sys
from time import asctime, localtime

# Number of parallel processes to run when conditioning data
global PARALLEL_PROCESSES
PARALLEL_PROCESSES = 8

# Maximum number of principal components scores shown in the triangle plot
# since the number of subplots in the triangle plot is n(n+1)/2, just having
# 15 results in 120 subplots in a single figure, which results in a segfault
# most of the time.
TRIANGLE_COMPONENTS = 12
# Max number of principal components plotted in the principal comonent summary 
# plot. (All the requested principal components will be plotted individually
# in the Principal_components subfolder )
MAX_ALL_PRINCIPAL_COMPONENTS = 20
####################################
# Other parameters
####################################
# Order of band-pass butterworth filter
BUTTERWORTH_ORDER = 4
# Number of max plotted principal components (scores scatterplots and waveforms)
MAX_PLOTTED_COMPONENTS = 5


################################################################################
# Default Values for parameters:
################################################################################

#####################
# Download options:
# Chunk size in seconds:
global segment_size
segment_size = 8
# chunk padding in seconds
download_overlap_seconds = 4
# Chunk padding in percent (1 = 100%)
download_overlap = 0.5

#####################

#####################
# PSD Options:
#####################
# Overlap between segments when computing the PSD
psd_overlap = 0.5

##############################
# GMM default parameters
################################
# Maximum number of clusters found by GMM
max_clusters = 10



# Load modules if help not requested or there are no arguments.
# Print help if no arguments or '-h'


from glob import glob

from pcat.utils import *

from pcat.data import retrieve_timeseries
from pcat.condition import *

from pcat.pipeline import pipeline
from pcat.finder import find_spikes, get_triggers, get_omicron_triglist
from pcat.pca import PCA, create_data_matrix, eigensystem, matrix_whiten
from pcat.gmm import gaussian_mixture, scatterplot, color_clusters, spike_time_series, matched_filtering_test, correlation_test, reconstructed_spike_time_series
from pcat.gmm import print_cluster_info, calculate_types, plot_psds, configure_subplot_time, configure_subplot_freq

def usage():
	'''
		Usage
	'''
	"""print "Usage:\n\tpcat (--time || --frequency) (--start start_time --end end_time || --list times_list)\n\
	 --frame frame_type -I IFO -c channel_name [--size segment_size]  \n\
	 [--filter] [--low low_frequency --high high_frequency]\n\
	 [--energy] [--whiten] [--nohighpass] [-v variables_number]\n\
	 [--padding_seconds padding || --padding_percent padding_perc]\n\
	 [--save_timeseries] [--reconstruct]"
	"""
	print '\033[1m' + "Usage:" + '\033[0m'
	print "\tpcat --IFO IFO --frame frame -c channel\\"
	print "--start start_time --end_end_time OR --list list_of_times\\"
	
	print "\t" + '\033[1m'+ "Time Domain options:" + '\033[0m'
	print "\t\t-t threshold [-v variable_n]"
	
	print '\033[1m'+ "\tFrequency Domain options:" + '\033[0m'
	print "\t\t[--size segment_size] [-v variable_n]"
	
	print "\nThe given time interval is processed and analyzed.\n"
	print "In time domain analysis the (whitened) time series is scanned"
	print "for transients, on which PCA is performed and the resulting"
	print "Principal Component Scores clustered with GMM."
	print "In frequency domain analysis PSDs for 'segment_size' seconds"
	print "of data are computed, PCA is performed and the resulting"
	print "Principal Component Scores are clustered with GMM.\n"
	
	print "#"*80
	
	
	print '\033[1m' + "Necessary Arguments:" + '\033[0m'
	
	print "  --time or --frequency"
	print "\tType of analysis being performed, either in time or frequency."
	print "\tTime analysis also requires the following arguments"
	print "\t'-t threshold' and '--whiten' or '--filter' ."
	print "\tFrequency does not require any extra arguments."
	
	print "  -I IFO, --IFO IFO"
	print "\tSpecify IFO, can be 'H' for Hanford or 'L' for Livingston."
	
	print "\t -c channel_name, --channel channel_name"
	print "\t\tChannel name, e.g.: L1:PSL-ISS_PDA_OUT_DQ."
	
	print "  --frame frame_type"
	print "\tFrame type, 'R' should be fine most times."
	print "\tWhen in doubt, check before running using ligo_data_find."
	
	print "\n" + '\033[1m' + "Interval to Analyze:" + '\033[0m'
	print " One of the following two:"
	print "   --start start_time --end end_time"
	print "\tStart AND end time expressed in GPS time, e.g. 1043107216"
	
	print "   --list times_list"
	print "\tA file containing a list of times to perform the analysis on."
	print "\tThe list should have two tab-separated columns, with"
	print "\tstart time on the first column and end time on the second"
	print "\tcolumn, in GPS time."
	
	print '\033[1m' + "Time Domain options:" + '\033[0m'
	print "   -t threshold, --threshold threshold"
	print "\tTrigger threshold in units of the standard deviation, e.g. 5.5. SNR threshold if used with --omicron."
	print "   --energy"
	print "\tNormalize identified transients to unit L2 norm"
	print "\tinstead of unit maximum amplitude (default)."
	
	
	print "\n" + '\033[1m' + "Data conditioning (time domain):" + '\033[0m'
	print "  --whitening whitens the data and applies an high-pass filter,"
	
	print "  --filter applies a band-pass filter. See below for more details."
	print "\n  *WARNING* --whitening downsamples the data to 4096Hz before"
	print "\tconditioning and analyzing. This means that the -v should be tuned"
	print "\taccordingly: e.g. choosing 1024 means that the number"
	print "\tof sampled seconds is 0.25s."
	print "\n\tThis can be changed through --resample new_frequency (or --noresample)."
	print "\n\tCondtioned files are saved in binary format, and can be used"
	print "\twith python/numpy using numpy's 'load()' function."
	
	print "   --filter "
	print "\tWith this option a fourth order butterworth"
	print "\tband-pass filter is applied."
	print "\tHigh and low cutoff frequencies have to be supplied"
	print "\tthrough --high and --low."
	
	print "   --high high_frequency, --low low_frequency\t (with --filter)"
	print "\tHigh and low cutoff frequency for band-pass filter (integers)"
	print "\t(Butterworth 4th Order)."
	
	print "   --whiten"
	print "\tWhiten and high-pass input data."
	print "\tWhitening is performed using the inverse PSD method,"
	print "\tthe PSD is computed using the median-mean-average algorithm."
	print "\tDefault overlap between neighbouring segments is 50%."
	
	print "   --highpasscutoff cutoff_frequency"
	print "\tCutoff frequency for the high pass filter (with --whiten)."
	
	print "   --nohighpass    (with --whiten)"
	print "\tDo not apply high-pass filter to input data."
	
	print "  "+"-"*int(74)
			
	print '\033[1m' + "Frequency domain options:" + '\033[0m'
	print "   --low low_frequency, --high high_frequency"
	print "\tOnly perform PCA on the frequency interval from "
	print "\tlow_frequency to high_frequency (integers) with a resolution"
	print "\tof 1 Hz."
	print "\t--low and --high, replace -v. The number of variables used"
	print "\tis given by high_frequency-low_frequency, use small value"
	print "\tfor the PCA algorithm to run faster."
	
	print '\033[1m' + "Optional arguments:" + '\033[0m'
	
	print "   --omicron\n\tUse omicron triggers. Use with -t SNR_threshold "
	print "   --triggers trigger_file\n\tGet triggers from the given file (single column with GPS times)."
	print "   --size segment_size\n\tSize in seconds of the chunks in which data is split."
	print "\tto be analyzed, must be larger than 1 (smaller is faster)."
	print "\tDefault is 8 sec for time analysis, 60 sec for frequency analysis."
	
	print "   --padding_seconds padding"
	print "\tPad the segment to be analyzed with extra seconds at the start and at the beginning,"
	print "\tin order to avoid filter artifacts."
	print "\tDefault 50% overlap in time domain analysis (e.g. 4 seconds overlap with"
	print "\t8 seconds long segments) and 0% overlap in frequency domain analysis."
		
	print "   --padding_percentage padding"
	print "\tSame as above, though expressed in percentage of segment_size"

	print "   --components components_number"
	print "\tNumber of components to be used when clustering in the"
	print "\tPrincipal Components space, integer, default is 40."
	print "\tThis also sets the number of principal components used"
	print "\tto reconstruct the glitches when plotting the time series"
	print "\tin the time-domain analysis when --reconstruct is used."
	print "\tThis might have to be tweaked for optimal results."
	print "\t --variance explained_variance"
	print "\tSimilar to the above, fixes the percentage of variance to include"
	print "\tin the analysis, hence fixing the number of principal components used."
	print "\tthis has to be a float between 0 and 1 (100%)."
	print "\tWhen --components is set to 0, explained variance is set to the default"
	print "\tvalue of 75%."
	
	print "   -m number, --maxclusters number"
	print "\tSpecifies the maximum number"
	print "\tof clusters. Integer, default is 10."
	
	print "   --discard_percentage percentage"
	print "\tSpecifies the minimum size of a cluster, classes with fewer than this percentage of the total number of glitches than this are discarded and classified as 'noise'. percentage has to be between 0 and 1."
	
	print "   -v variables_n, --variables variables_n"
	print "\tIf performing time-domain analysis, this sets the time resolution"
	print "\ti.e. the temporal length of the sampled transients.\n"
	print "\tThe length of the sampled transients in seconds is"
	print "\t\tvariables_n/sampling_frequency"
	print "\twith sampling_frequency being 4096 Hz if --whiten"
	print "\tor the input value if --resample.\n"
	
	print "\tIf in frequency-domain, this sets frequency resolution of "
	print "\tthe computed spectrum: resolution equals to"
	print "\t\tnyquist_frequency/variables_n. "
	print "\t(where the Nyquist frequency is half of the sampling frequency."
	print "\tWhen performing frequency-domain analysis, for faster computation,"
	print "\tvariables_n should be a power of two."
	print "\tDefault values are 512 for time-domain and 2048 for frequency-domain."
	print "\tThe higher this value, the slower the PCA decomposition."
	
	print "   --reconstruct"
	print "\tIf set, then glitches' time series are reconstructed using components_number "
	print "\tprincipal components (set with --components or --variance)."
	print "\tOnly using the first few principal components will reduce noise in the time series"
	print "\tand make the 'true' shape of the glitch more clear."
	
	print "   --save_timeseries"
	print "\tSave raw time series of the interval being analyzed."
	print "\tThe saved files (binary) can be used with python/numpy,"
	print "\tusing numpy's 'load()'"
	
	print "  --extra_features"
	print "\tUse extra features (central frequency, peak frequency, Energy, duration)"
	print "\tto compute PCA."
    
    
	print "   --noplot"
	print "\tDo not plot transients/PSDs (makes run faster)"
	
	print "   --silent"
	print "\tDo not display progress bars"
	
	print "  "+"-"*int(74) + "\n"





################################################################################

##############################
# Helper routines:           #
##############################
	
def check_options_and_args(argv):
	global components_number, psd_overlap, max_clusters, segment_size, download_overlap
	global LIST, CUSTOM_OUT, FILTER , WHITEN, HIGH_PASS, HIGH_PASS_CUTOFF, SAVE_TIMESERIES, NORESAMPLE, RESAMPLE
	global HIGH_PASS
	
	global variables, channel, IFO, sampling
	global frame_type, variables, normalization
	global low, high, output_name, threshold, time_resolution, components_number
	
	global ANALYSIS, ANALYSIS_FREQUENCY, CLEAN, RECONSTRUCT, NOPLOT, SILENT
	global AUTOCHOOSE_COMPONENTS, VARIANCE_PERCENTAGE
	
	global EXTRA_FEATURES
	global OMICRON
	
	EXTRA_FEATURES = False
	LIST = False
	CUSTOM_OUT = False
	FILTER = False
	WHITEN = False
	SAVE_TIMESERIES = False
	RECONSTRUCT = False
	components_number = 40
	AUTOCHOOSE_COMPONENTS = False
	
	SILENT = False
	NOPLOT = False
	CLEAN = False
	NORESAMPLE = False
	
	# Boolean: apply High Pass filter

	HIGH_PASS = True
	
	# Use omicron triggers
	OMICRON = False
	# Decide if data is resampled to ANALYSIS_FREQUENCY (if not supplied through
	# --resample, then it's set to 4096.0 after the argument parsing, see below)
	RESAMPLE = True
	SILENT = False
	# Booleans 
	
	global TRIGGERLIST
	global TRIGGERFILE
	TRIGGERLIST = False
	
	global start_time, end_time, times_list, times, total, download_overlap_seconds
	global glitchgram_start, glitchgram_end
	glitchgram_start, glitchgram_end = None, None
	
	low, high = None, None
	
	normalization = "amplitude"
	
	if len(argv[1:]) == 0:
		print "No arguments."
		usage()
		sys.exit(1)
	try:
		opts, args = getopt.getopt(argv[1:], "hc:I:v:t:m:", [ "help", 'threshold=', 'channel=', 'IFO=',\
														'variables=', 'frame=', 'start=',\
		 												'end=', 'padding_seconds=', "padding_percentage=", 'psd_overlap=',\
		 												'high=', 'low=', 'list=', 'components=', 'time', 'frequency',\
														'filter', 'maxclusters=', 'whiten', 'size=', 'nohighpass', 'resample=',\
														'highpasscutoff=', 'energy', "save_timeseries", "clean", "noresample",\
														"reconstruct", 'noplot', 'silent', "glitchgram_start=", "glitchgram_end=",\
														"variance=", "triggers=", "discard_percent=", "omicron"])
	except getopt.error, msg:
		print msg
		sys.exit(1)
	
	# option processing
	for option, value in opts:
		if option in ( "-h", "--help" ):
			usage()
			sys.exit(1)
		elif option in ( "-v", "--variables" ):
			variables = int(value)
		elif option in ( "-t", "--threshold" ):
			threshold = float(value)
		elif option in ( "--resample" ):
			ANALYSIS_FREQUENCY = float(value)
		elif option in ( "--noresample" ):
			NORESAMPLE = True
		elif option in ( "-c", "--channel" ):
			channel = value
		elif option in ( "--energy" ):
			normalization = "energy"
		elif option in ( "-I", "--IFO" ):
			IFO = value
		elif option in ( "--start" ):
			start_time = int(value)
		elif option in ( "--end" ):
			end_time = int(value)
		elif option in ( "--padding_percentage" ):
			download_overlap = float(value)/100.0
		elif option in ( "--padding_seconds" ):
			download_overlap_seconds = int(value)
		elif option in ( "--maxclusters", "-m" ):
			max_clusters = int(value)
		elif option in ( "--psd_overlap" ):
			psd_overlap = float(value/100.0)
		elif option in ( "--frame" ):
			frame_type = value
		elif option in ( "--components" ):
			components_number = int(value)
		elif ( option == "--high" ):
			high = int(value)
		elif ( option == "--low" ):
			low = int(value)
		elif ( option == "--size" ):
			segment_size = int(value)
		elif option in ( "--list" ):
			LIST = True
			times_list = value
		elif option in ( '--time' ):
			ANALYSIS = 'time'
		elif option in ( '--frequency' ):
			ANALYSIS = 'frequency'
		elif option in ( '--filter' ):
			FILTER = True
		elif option in ( '--whiten' ):
			WHITEN = True
		elif option in ( "--nohighpass" ):
			HIGH_PASS = False
		elif option in ( "--highpasscutoff" ):
			HIGH_PASS_CUTOFF = float(value)
		elif option in ( "--save_timeseries" ):
			SAVE_TIMESERIES = True
		elif option == "--clean":
			CLEAN = True
		elif option == "--reconstruct":
			RECONSTRUCT = True
		elif option == "--triggers":
			TRIGGERLIST = True
			TRIGGERFILE = os.path.abspath(value)
		elif option == "--noplot":
			NOPLOT = True
		elif option == "--silent":
			SILENT = True	
		elif option == "--glitchgram_start":
			glitchgram_start = int(value)
		elif option == "--glitchgram_end":
			glitchgram_end = int(value)
		elif option == "--variance":
			AUTOCHOOSE_COMPONENTS = True
			VARIANCE_PERCENTAGE = float(value)
			components_number = 0
		elif option in ( "--discard_percent" ):
			global discard_percent
			discard_percent = float(value)
			if (discard_percent >= 1) or (discard_percent < 0):
				print "Usage: --discard_percent percent, 'percent' has to be between 0 and 1"
				print "Quitting."
				sys.exit()
		elif option in ( "--extra_features" ):
			EXTRA_FEATURES = True
		elif option == "--omicron":
			OMICRON = True
		else:
			print "Unknown option."
			sys.exit()
		
		
	######################################################
	# Checks arguments
	####################################################
	if not ( any( '--list' in o for o in opts) ):
		if ( any( '--start' in o for o in opts) and any('--end' in o for o in opts) ):
			# To add?: check validity of start time and end time
			if ( start_time >= end_time ):
				print "Check start and end time. Quitting."
				sys.exit()
	
	if not ( any( "--components" in o for o in opts)):
		if not (any( '--variance' in o for o in opts) ):
			print "Either --components (number of principal components used for clustering)"
			print "or --variance (percentage of explained variance used) have to be"
			print "supplied. Quitting."
			sys.exit()
		elif (any('--variance' in o for o in opts)):
			if (VARIANCE_PERCENTAGE <= 0) or (VARIANCE_PERCENTAGE>1.0):
				print "Variance percentage has to be in the ]0,1] interval."
				print "Quitting."
				sys.exit()
	elif ( any( "--components" in o for o in opts)):
		if (components_number > variables):
			print "The number of principal components used for clustering has to be lower"
			print "or equal than the number of variables. Quitting."
			sys.exit()
	
	if (components_number == 0) and not AUTOCHOOSE_COMPONENTS:
		# If the number of supplied components is zero, fall back to 75% 
		# explained variance.
		AUTOCHOOSE_COMPONENTS = True
		VARIANCE_PERCENTAGE = 0.75
	
	if not ( any( flag in o for flag in [ "--start", "--end", "--list"] for o in opts )):
		print "Start and end GPS time or a list of GPS times have to be supplied. Quitting."
		sys.exit()
	elif not any('--list' in o for o in opts):
		if not ( any( "--start" in o for o in opts) and any("--end" in o for o in opts) ):
			print "Both --start and --end have to be supplied. Quitting."
			sys.exit()
	elif ( any( flag in o for flag in ['--start', '--end'] for o in opts) and any('--list' in o for o in opts )):
			print "Choose one between --list or --start and --end. Quitting."
			sys.exit()	
	
	if not any( flag in o for flag in [ "--channel", "-c"] for o in opts ):
		print "Channel name has to be supplied through '--channel' or '-c'. Quitting."
		sys.exit()
	if not ( any( flag in o for flag in ['--IFO', "-I"] for o in opts ) ):
		print "IFO ('L', 'H' or 'H1_R') has to be supplied"
		print "through the --IFO or -I flags. Quitting."
		sys.exit()
	
	if ( all( flag in o for flag in ['--triggers', "-t"] for o in opts ) ):
		print "Warning: both --triggers and -t (--threshold) options are being used. -t is ignored."
		
	if not ( any( flag in o for flag in ['--time', "--frequency"] for o in opts ) ):
		print "Analysis type (time domain or frequency domain) has to be supplied"
		print "through the --time or --frequency flags. Quitting."
		sys.exit()
	
	if not any( flag in o for flag in ['--frame'] for o in opts ):
		print "Frame type has to be supplied (usually 'R' for Livingston or 'H1_R' for Hanford)."
		print "Check with ligo_data_find when in doubt. Quitting."
		sys.exit()
	
	if ( ANALYSIS == "time") and ( FILTER ):
		if not ( any( flag in o for flag in ['--high', '--low'] for o in opts ) ):
			print "Filter parameters (low and high cutoff frequencies) have to be supplied. Quitting."
			sys.exit()
	
	if ( ANALYSIS == "time") :
		if not ( any( flag in o for flag in ['-t', '--threshold'] for o in opts ) ) and not (any("--triggers" in o for o in opts)):
			if OMICRON:
				print "SNR threshold has to be supplied through the -t"
			else:
				print "Threshold (in units of standard deviation) has to be supplied through the -t"
			print "or --threshold option. Quitting."
			sys.exit()
		if ( any( "--whiten" in o for o in opts) and any('--filter' in o for o in opts) ):
			print "Please choose between --whiten and --filter."
			print "Quitting."
			sys.exit()
	
	# Default fallback value for discard_percent: 5%
	try:
		if discard_percent:
			pass
	except:
		discard_percent = 0.05
	
	############################################################################
	# End of data checking
	############################################################################
	
	# Create a list with the time intervals to be analyzed
	# times = [ [start1, end1], [start2, end2], ... ]
	times = []
	if LIST:
		f = open( times_list, "r")
		tmp = ( f.read().strip() ).split("\n")
		f.close()
		for element in tmp:
			times.append( [int(a) for a in element.split()] )
	else:
		times.append( [start_time, end_time] )
	
	
	# Retrieve sampling frequency for the given channel by retrieving a small 
	# portion of the data. Sampling frequency is accessed through the 'fs' key
	# of the 'data' dictionary (see `pcat.data` for the definition
	# of retrieve_timeseries)
	start = times[0][0]
	try:
		data = retrieve_timeseries(start, start+32, channel, IFO, frame_type)
	except RuntimeError:
		assert False, "Error retrieving data. Check channel name, frame type and IFO."
	
	sampling = data['fs']
	if NORESAMPLE:
		ANALYSIS_FREQUENCY = sampling
	############################################################################
	
	
	
	# This part deals with the "bands" analysis of PCAT and is used
	# to have the correct definitions when running PCAT on fequency bands
	# Append "_bands" to ANALYSIS.
	if ( ( ANALYSIS == "frequency" ) and any( flag in o for flag in ['--high', '--low'] for o in opts ) ):
		if ( any("--high" in o for o in opts) and any("--low" in o for o in opts) ):
			ANALYSIS = "frequency_bands"
		else:
			print "If bands analysis is being performed, both low and high frequencies\n\
	have to be supplied through --low and --high. Quitting."
			sys.exit()
	
	# Compute the overlap in seconds between neighouring segments
	# if the download overlap has not been supplied through the
	# --download_overlap_seconds option.
	if ( "--padding_percentage" in argv ):
		download_overlap_seconds = int(segment_size*download_overlap)
	elif ( "--padding_seconds" in argv):
		pass
	elif ( "--size" in argv ):
		download_overlap_seconds = int(segment_size*download_overlap)
		
	# If variable input has not been supplied, set them to default values:
	if not ( any( flag in o for flag in [ '--variables', "-v" ] for o in opts ) ):
		if ( ANALYSIS == "time" ):
			variables = 512
		elif ( ANALYSIS == "frequency"):
			variables = 2048
	
	if ( ANALYSIS == "frequency_bands" ):
		# If band analysis, compute the spectrum at 1Hz resolution, then 
		# only analyze the the needed band
		# Variables number (given resolution is) [(f_s/2)/res]+1
		variables = (sampling//2)//1 +1
	
	# Set ANALYSIS_FREQUENCY to default (4096.0) if no other options have been
	# supplied
	if ( "--resample" not in argv) and not NORESAMPLE:
		ANALYSIS_FREQUENCY = 4096.0
		
	if ( "frequency" in ANALYSIS):
		if not ( any("--size" in o for o in opts)):
			segment_size = 60
		if ( any("--padd" not in o for o in opts) ):
			download_overlap = 0.0
			download_overlap_seconds = 0
			
	# Count the total number of analyzed seconds
	total = 0
	for element in times:
		total += int(element[1])-int(element[0])
		
	# Set default value for find_spikes()'s time_resolution
	time_resolution = int(variables/2)
	



def get_server_url():
	"""
		This retrieves the hostname on the server this program is being run on
		in order to give an URL for the output of PCAT.
	"""
	hostname = getstatusoutput( "echo $(hostname)| sed \"s/-[^.]*/-jobs/\"" )[1]
	if ( ".edu" ) in hostname:
		server = "https://"+hostname+"/"
	else:
		server = "https://"+getstatusoutput("echo $(hostname) | sed \"s/-[^.]*/-jobs/\" | xargs -i echo {}.$(dnsdomainname)")[1]+"/"
	
	# The following line is used to give the correct URL when running PCAT 
	# through condor
	# If the string "node" is in the URL, then remove the "node*" part and
	# substitute it with "ldas-jobs"
	if ("node") in server:
		tmp = join(server.split("/")[3:], ".")
		if ( "cit" in server ):
			server = "https://ldas-jobs.ligo.caltech.edu/" + tmp
		elif ("ligo-la" in server):
			server = "https://ldas-jobs.ligo-la.caltech.edu/" + tmp
		elif ("ligo-wa" in server):
			server = "https://ldas-jobs.ligo-wa.caltech.edu/" + tmp
		else:
			server = "Error parsing url: \t"  + tmp
	return server


def print_parameters():
	'''
	This function prints the parameters of the run.
	'''
	global times, total, units, variables
	global ANALYSIS_FREQUENCY
	print "#"*int(0.8*frame_width)
	
	print "Parameters for this run:"
	
	
	if ( "time" in ANALYSIS ):
		print "Time Domain Analysis:"
	elif ( "frequency" in ANALYSIS  ):
		print "Frequency Domain Analysis:"
	print "\t - General:\t"
	if LIST:
		print "\t\t List of times:\t\t\t", times_list 
	else:
		print "\t\t Start time:\t\t\t", start_time, "("+str(getstatusoutput("tconvert "+str(start_time) )[1]) + ")\n\
		 End time:\t\t\t", end_time, "("+str(getstatusoutput("tconvert "+str(end_time) )[1]) + ")"
	units = "%i seconds"
	global dividend
	dividend = 1.0
	if ( total > 60.0 ):
		dividend *= 60.0
		units = "minutes" 
		if ( total/dividend > 60.0 ):
			dividend *= 60.0
			units = "hours" 
			if ( total/dividend > 24.0 ):
				dividend *= 24.0
				units = "days"
	print "\t\t Total analyzed time:\t\t{0:.2f} {1}".format(total/dividend, units)
	print "\t\t Channel name:\t\t\t", channel
	print "\t\t IFO:\t\t\t\t", IFO
	print "\t\t Data Type:\t\t\t", frame_type
	print "\t\t Chunk size:\t\t\t", segment_size, "seconds"
	print "\t\t Padding:\t\t\t", download_overlap_seconds, "seconds"
	print "\t\t (Total size: ", segment_size+2*download_overlap_seconds, "seconds)"
	print "\t\t Sampling frequency:\t\t", sampling
	if (RESAMPLE and ( "time" in ANALYSIS) and ( sampling > ANALYSIS_FREQUENCY) ):
		print "\t\t (Downsampled to %.1f for analysis)" % ANALYSIS_FREQUENCY
	print ""
	if ( "time" in ANALYSIS ):
		if FILTER:
			print "\t - Butterworth filter:"
			print "\t\t Low Cutoff Frequency:\t\t", low
			print "\t\t High Cutoff Frequency:\t\t", high
			print 
		if WHITEN:
			print "\t\t Whitening:\t\t\tON"
			if HIGH_PASS:
				print "\t\t High Pass Cutoff:\t\t", HIGH_PASS_CUTOFF
			else:
				pass
		else:
			print "\t\t Whitening:\t\t\tOFF"
			if HIGH_PASS:
				print "\t\t High Pass Cutoff:\t\t", HIGH_PASS_CUTOFF
		print "\t - Trigger parameters:\n\
		 Number of variables:\t\t", variables
		if ( sampling > ANALYSIS_FREQUENCY ):
			seconds_per_trigger = float(variables)/ANALYSIS_FREQUENCY
		else:
			seconds_per_trigger = float(variables)/sampling
		print "\t\t (%.3f s per trigger)" % seconds_per_trigger
		if TRIGGERLIST:
			print "\t\t Trigger List:\t\t\t", os.path.abspath(TRIGGERFILE)
		elif OMICRON:
			print "\t\t Threshold: SNR>=\t\t\t{0} (Using Omicron triggers)".format(threshold)
		else:
			print "\t\t Threshold:\t\t\t", threshold
		if RECONSTRUCT and not AUTOCHOOSE_COMPONENTS:
			print "\t\t Identified transients plots:\tReconstructed using the"
			print "\t\t\t\t\t\tfirst {0} principal components".format(components_number)
		elif AUTOCHOOSE_COMPONENTS and RECONSTRUCT:
			print "\t\t Identified transients plots:\tReconstructed using the"
			print "\t\t\t\t\t\tusing principal component accounting"
			print "\t\t\t\t\t\tfor {0:.1%} of the variance".format(VARIANCE_PERCENTAGE)
		else:
			print "\t\t Identified transients plots:\tRaw time series"
		print "\t\t Noise class threshold:\t {0:.1f}%\n\t\t(classes with fewer than this percentage of the total number of glitches than this are discarded and classified as 'noise')".format(discard_percent*100)
	elif ( "frequency" in ANALYSIS ):
		print "\t- Frequency Domain:\n"
		# The 'resolution' variable is used when computing the PSD, and is not 
		# the actual resolution of the PSD, but yields the correct result
		# (I know, this is complicated)
		global resolution
		resolution = sampling/(2*(variables-1))
		if ( "bands" in ANALYSIS ):
			# In bands analysis the spectrum is computed with a 1Hz resolution.
			print "\t\tPSD resolution:\t\t\t%.2f Hz" % (resolution)
			print "\t\tBand:\t\t\t\t%i to %i Hz (%i points)" % (low, high, int(high-low+1))
		else:
			print "\t\tPSD resolution:\t\t\t%.2f Hz (%i points)" % ( resolution, variables )
	print 
	print "\t - PCA and GMM:"
	if AUTOCHOOSE_COMPONENTS:
		print "\t\tPercentage of total"
		print "\t\tvariance explained:\t\t{0:.2%}".format(VARIANCE_PERCENTAGE)
	else:
		print "\t\tComponents Number:\t\t", components_number
	print "\t\t Maximum Clusters:\t\t", max_clusters
	
	global CLEAN
	if CLEAN:
		print "\tRemoving existing data folders before running pipeline."
	
	if SILENT:
		print "\tSILENT run (no progress bars)"
	print "\n\t- Log file:\n\t  {0}\n".format(log_name)
	
	print "#"*int(0.8*frame_width)
	
	# end of print_parameters()


def main():
	pipeline(sys.argv)
	
if __name__ == "__main__":
	main()
